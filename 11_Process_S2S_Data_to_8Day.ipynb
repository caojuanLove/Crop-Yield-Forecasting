{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "525cedda-ca1c-4440-a0bd-27acb64e8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wind_speed_and_vpd(ds_10u, ds_10v, ds_2d, ds_2t):\n",
    "    # 重命名风速分量变量\n",
    "    ds_10u = ds_10u.rename({'u10': 'wind_speed_u'})\n",
    "    ds_10v = ds_10v.rename({'v10': 'wind_speed_v'})\n",
    "    # 计算风速\n",
    "    wind_speed = np.sqrt(ds_10u['wind_speed_u']**2 + ds_10v['wind_speed_v']**2)\n",
    "    # 将风速添加到一个新的 Dataset 中\n",
    "    ds_wind_speed = xr.Dataset({'wind_speed': wind_speed})\n",
    "    \n",
    "    # 重命名温度和露点温度变量\n",
    "    ds_2d = ds_2d.rename({'d2m': 'dewpoint_temperature'})\n",
    "    ds_2t = ds_2t.rename({'t2m': 'temperature'})\n",
    "    \n",
    "    # 将温度从开尔文转换为摄氏度\n",
    "    T_celsius = ds_2t['temperature']# - 273.15\n",
    "    Td_celsius = ds_2d['dewpoint_temperature']# - 273.15\n",
    "    \n",
    "    # 计算相对湿度\n",
    "    # 计算相对湿度，并转换为百分比\n",
    "    RH = np.exp((17.625 * Td_celsius) / (Td_celsius + 243.04)) / np.exp((17.625 * T_celsius) / (T_celsius + 243.04))\n",
    "\n",
    "    # 计算饱和蒸汽压 e_s\n",
    "    e_s = 6.107 * 10 ** (7.5 * T_celsius / (T_celsius + 237.3))\n",
    "    \n",
    "    # 计算实际蒸汽压\n",
    "    e_a = e_s * RH\n",
    "    \n",
    "    # 计算 VPD\n",
    "    vpd = e_s - e_a\n",
    "    ds_vpd = xr.Dataset({'vpd': vpd})\n",
    "    \n",
    "    return ds_wind_speed, ds_vpd\n",
    "\n",
    "\n",
    "\n",
    "def calculate_days_between(start_date_str, end_date_str, date_format=\"%Y%m%d\"):\n",
    "    \"\"\"\n",
    "    计算两个日期字符串之间的天数（包括结束日期前一天）。比如20220901到20220922，计算出来的是21天，即不包括最后一天\n",
    "    \n",
    "    :param start_date_str: 开始日期字符串\n",
    "    :param end_date_str: 结束日期字符串\n",
    "    :param date_format: 日期字符串的格式，默认为 \"%Y%m%d\"\n",
    "    :return: 两个日期之间的天数\n",
    "    \"\"\"\n",
    "    # 将日期字符串转换为日期对象\n",
    "    start_date = datetime.strptime(start_date_str, date_format)\n",
    "    end_date = datetime.strptime(end_date_str, date_format)\n",
    "    \n",
    "    # 计算日期差\n",
    "    days_between = (end_date - start_date).days\n",
    "    \n",
    "    return days_between\n",
    "    \n",
    "def create_directory(path):\n",
    "    \"\"\"\n",
    "    创建目录（及其所有父目录，如果它们不存在）。\n",
    "    \n",
    "    :param path: 目录路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "       # print(f\"Directory '{path}' created successfully.\")\n",
    "    except OSError as error:\n",
    "        pass\n",
    "    \n",
    "def process_temperature_data(ds_pf_mn2t6, ds_pf_mx2t6):  \n",
    "    # 初始化列表来存储最小和最大温度值  \n",
    "    min_temps = []  \n",
    "    max_temps = []  \n",
    "      \n",
    "    # 遍历年份  \n",
    "\n",
    "        # 选择特定年份的数据  \n",
    "    ds_pf_mn2t61 = ds_pf_mn2t6#.isel(time=time1)  \n",
    "    ds_pf_mx2t61 = ds_pf_mx2t6#.isel(time=time1)  \n",
    "      \n",
    "    # 转换 valid_time 为 pandas datetime，减去6小时，然后格式化为日期字符串  \n",
    "    ds_pf_mn2t61['step'] = (pd.to_datetime(ds_pf_mn2t61['valid_time']) - pd.to_timedelta(6, unit='h')).strftime(\"%Y-%m-%d\")  \n",
    "    ds_pf_mx2t61['step'] = (pd.to_datetime(ds_pf_mx2t61['valid_time']) - pd.to_timedelta(6, unit='h')).strftime(\"%Y-%m-%d\")  \n",
    "      \n",
    "    # 按 step 进行分组并求最小值和最大值  \n",
    "    ds_pf_mn2t61_grouped = ds_pf_mn2t61.groupby('step').min()  # 注意这里应该是 'time' 而不是 'step'，假设 'time' 是时间维度  \n",
    "    ds_pf_mx2t61_grouped = ds_pf_mx2t61.groupby('step').max()  \n",
    "      \n",
    "    # 将结果添加到列表中  \n",
    "    min_temps.append(ds_pf_mn2t61_grouped['mn2t6'].values)  \n",
    "    max_temps.append(ds_pf_mx2t61_grouped['mx2t6'].values)  \n",
    "      \n",
    "    # 使用 numpy.stack 沿最后一个轴合并数据  \n",
    "    min_temps_4d = min_temps  \n",
    "    max_temps_4d = max_temps \n",
    "      \n",
    "    # 如果有必要，重新排列维度以匹配期望的维度顺序（例如，时间维度在前）  \n",
    "      \n",
    "    return max_temps_4d, min_temps_4d  \n",
    "\n",
    "\n",
    "def read_pf_data(pathto, origen, region, years):\n",
    "    ds_pf_mn2t6 = xr.open_dataset(f'{pathto}\\\\{origen}_mn2t6_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_mn2t6 = ds_pf_mn2t6 - 273.15\n",
    "   # ds_pf_mn2t6 = ds_pf_mn2t6.mean(dim='number')\n",
    "    \n",
    "    ds_pf_mx2t6 = xr.open_dataset(f'{pathto}\\\\{origen}_mx2t6_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_mx2t6 = ds_pf_mx2t6 - 273.15\n",
    "    #ds_pf_mx2t6 = ds_pf_mx2t6.mean(dim='number')\n",
    "    \n",
    "    ds_pf_2d = xr.open_dataset(f'{pathto}\\\\{origen}_2d_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_2d = ds_pf_2d - 273.15\n",
    "    #ds_pf_2d = ds_pf_2d.mean(dim='number')\n",
    "    \n",
    "    ds_pf_2t = xr.open_dataset(f'{pathto}\\\\{origen}_2t_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_2t = ds_pf_2t - 273.15\n",
    "    #ds_pf_2t = ds_pf_2t.mean(dim='number')\n",
    "    \n",
    "    ds_pf_tp = xr.open_dataset(f'{pathto}\\\\{origen}_tp_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_tp = ds_pf_tp.diff(dim='step')\n",
    "    ds_pf_tp = ds_pf_tp.where(ds_pf_tp > 0, 0)\n",
    "    #ds_pf_tp = ds_pf_tp.mean(dim='number')\n",
    "    \n",
    "    ds_pf_ssr = xr.open_dataset(f'{pathto}\\\\{origen}_ssr_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_ssr = ds_pf_ssr / 86400\n",
    "    #ds_pf_ssr = ds_pf_ssr.mean(dim='number')\n",
    "    \n",
    "    ds_pf_10u = xr.open_dataset(f'{pathto}\\\\{origen}_10u_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_pf_10v = xr.open_dataset(f'{pathto}\\\\{origen}_10v_{region}_pf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    #ds_pf_10u = ds_pf_10u.mean(dim='number')\n",
    "    #ds_pf_10v = ds_pf_10v.mean(dim='number')\n",
    "    \n",
    "    ds_wind_speed, ds_vpd = calculate_wind_speed_and_vpd(ds_pf_10u, ds_pf_10v, ds_pf_2d, ds_pf_2t)\n",
    "    \n",
    "    return ds_pf_mx2t6, ds_pf_mn2t6, ds_pf_2t, ds_pf_tp, ds_wind_speed, ds_vpd, ds_pf_ssr\n",
    "\n",
    "\n",
    "def read_cf_data(pathto, origen, region, years):\n",
    "    ds_cf_mn2t6 = xr.open_dataset(f'{pathto}\\\\{origen}_mn2t6_{region}_cf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_mn2t6 = ds_cf_mn2t6 - 273.15\n",
    "   # ds_cf_mn2t6 = ds_cf_mn2t6.mean(dim='number')\n",
    "    \n",
    "    ds_cf_mx2t6 = xr.open_dataset(f'{pathto}\\\\{origen}_mx2t6_{region}_cf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_mx2t6 = ds_cf_mx2t6 - 273.15\n",
    "   # ds_cf_mx2t6 = ds_cf_mx2t6.mean(dim='number')\n",
    "    \n",
    "    ds_cf_2d = xr.open_dataset(f'{pathto}\\\\{origen}_2d_{region}_cf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_2d = ds_cf_2d - 273.15\n",
    "    #ds_cf_2d = ds_cf_2d.mean(dim='number')\n",
    "    \n",
    "    ds_cf_2t = xr.open_dataset(f'{pathto}\\\\{origen}_2t_{region}_cf_forecasttimefcst_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_2t = ds_cf_2t - 273.15\n",
    "   # ds_cf_2t = ds_cf_2t.mean(dim='number')\n",
    "    \n",
    "    ds_cf_tp = xr.open_dataset(f'{pathto}\\\\{origen}_tp_{region}_cf_forecasttimefcstt_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_tp = ds_cf_tp.diff(dim='step')\n",
    "    ds_cf_tp = ds_cf_tp.where(ds_cf_tp > 0, 0)\n",
    "  #  ds_cf_tp = ds_cf_tp.mean(dim='number')\n",
    "    \n",
    "    ds_cf_ssr = xr.open_dataset(f'{pathto}\\\\{origen}_ssr_{region}_cf_forecasttimefcstt_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_ssr = ds_cf_ssr / 86400\n",
    "  #  ds_cf_ssr = ds_cf_ssr.mean(dim='number')\n",
    "    \n",
    "    ds_cf_10u = xr.open_dataset(f'{pathto}\\\\{origen}_10u_{region}_cf_forecasttimefcstt_{years}.grib', engine='cfgrib')\n",
    "    ds_cf_10v = xr.open_dataset(f'{pathto}\\\\{origen}_10v_{region}_cf_forecasttimefcstt_{years}.grib', engine='cfgrib')\n",
    "   # ds_cf_10u = ds_cf_10u.mean(dim='number')\n",
    "  #  ds_cf_10v = ds_cf_10v.mean(dim='number')\n",
    "    \n",
    "    ds_wind_speed, ds_vpd = calculate_wind_speed_and_vpd(ds_cf_10u, ds_cf_10v, ds_cf_2d, ds_cf_2t)\n",
    "    \n",
    "    return ds_cf_mx2t6, ds_cf_mn2t6, ds_cf_2t, ds_cf_tp, ds_wind_speed, ds_vpd, ds_cf_ssr\n",
    "\n",
    "def process_df_arrays(ds_pf_2t, ds_pf_tp, ds_pf_ssr, ds_wind_speed, ds_vpd):\n",
    "    # 提取变量的值\n",
    "    t2m_values = ds_pf_2t['t2m'].values\n",
    "    tp_values = ds_pf_tp['tp'].values\n",
    "    ssr_values = ds_pf_ssr['ssr'].values\n",
    "    \n",
    "    # 计算太阳辐射逐小时差分，在二维step上面计算\n",
    "    new_array = np.zeros_like(ssr_values)\n",
    "    new_array[ :, 0, :] = ssr_values[:, 0, :]\n",
    "    new_array[:, 1:, :] = np.diff(ssr_values, axis=1)\n",
    "    ssr_processed = new_array\n",
    "    \n",
    "    # 提取风速和蒸发压亏的值\n",
    "    wind_speed_values = ds_wind_speed['wind_speed'].values\n",
    "    vpd_values = ds_vpd['vpd'].values\n",
    "    \n",
    "    return t2m_values, tp_values, ssr_processed, wind_speed_values, vpd_values\n",
    "\n",
    "\n",
    "\n",
    "def process_cf_arrays(ds_cf_2t, ds_cf_tp, ds_cf_ssr, ds_wind_speed, ds_vpd):\n",
    "    # 提取变量的值\n",
    "    t2m_values = ds_cf_2t['t2m'].values\n",
    "    tp_values = ds_cf_tp['tp'].values\n",
    "    ssr_values = ds_cf_ssr['ssr'].values\n",
    "    \n",
    "    # 计算太阳辐射逐小时差分\n",
    "    new_array = np.zeros_like(ssr_values)\n",
    "    new_array[0, :, :] = ssr_values[ 0, :, :]\n",
    "    new_array[1:, :, :] = np.diff(ssr_values, axis=0)\n",
    "    ssr_processed = new_array\n",
    "    \n",
    "    # 提取风速和蒸发压亏的值\n",
    "    wind_speed_values = ds_wind_speed['wind_speed'].values\n",
    "    vpd_values = ds_vpd['vpd'].values\n",
    "    \n",
    "    return t2m_values, tp_values, ssr_processed, wind_speed_values, vpd_values\n",
    "\n",
    "def extract_dates(inputpath_base,institution,region):\n",
    "    #返回开始和结束日期的周数和对应的天数，以及选中的VI\n",
    "    file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori',institution,'CommonYear_Week.txt')\n",
    "    inpath_dates = os.path.join(inputpath_base, '01_data', '05_buildmodel', '02_extractdates', 'gs_three_periods.txt')\n",
    "    # 从文件中读取行并去除两端空白字符\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "    # 从另一个文件中读取起始点和收获点\n",
    "    file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori',institution,'CommonYear_Week.txt')\n",
    "    inpath_dates = os.path.join(inputpath_base, '01_data', '05_buildmodel', '02_extractdates', 'gs_three_periods.txt')\n",
    "    # 从文件中读取行并去除两端空白字符\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "    # 从另一个文件中读取起始点和收获点\n",
    "    gs_infornamtion = pd.read_csv(inpath_dates, sep='\\t', header=None)\n",
    "    gs_infornamtion.columns = ['start_point', 'peak', 'harvest_point','VI_select2','regions']\n",
    "    harvest_point = gs_infornamtion[gs_infornamtion['regions']==region]['harvest_point'].values[0]\n",
    "    start_point = gs_infornamtion[gs_infornamtion['regions']==region]['start_point'].values[0]\n",
    "    VI_select2 = gs_infornamtion[gs_infornamtion['regions']==region]['VI_select2'].values[0]\n",
    "    \n",
    "    # 将收获点和起始点的字符串转换为整数\n",
    "    harvest_point = int(harvest_point) # 汇聚为8天是往后汇聚的，比如01-01，是指的01-01到01-08的汇聚指标\n",
    "    start_point = int(start_point)\n",
    "    \n",
    "    # 根据收获点和起始点的索引，从lines中取得对应的日期\n",
    "    if harvest_point ==46:\n",
    "        harvest_date_doy = '-'+'12-31'\n",
    "    else:\n",
    "        harvest_date_doy = '-' + lines[harvest_point]\n",
    "    start_date_doy = '-' + lines[start_point]\n",
    "    # 返回起始日期和收获日期\n",
    "    return start_point,harvest_point,start_date_doy, harvest_date_doy,VI_select2\n",
    "\n",
    "\n",
    "def process_climate_data(data_new, year, T_upper, T_lower, dynamic_features, soil_feature, loc_feature, Year_feature, union_feature):\n",
    "    # 选择列\n",
    "    Tmin_columns = [col for col in data_new.columns if '_Tmin' in col]\n",
    "    Tmin = data_new[Tmin_columns].values\n",
    "    Tmean_columns = [col for col in data_new.columns if '_Tmean' in col]\n",
    "    Tmean = data_new[Tmean_columns].values\n",
    "    Tmax_columns = [col for col in data_new.columns if '_Tmax' in col]\n",
    "    Tmax = data_new[Tmax_columns].values\n",
    "    Pre_columns = [col for col in data_new.columns if '_Pre' in col]\n",
    "    Pre = data_new[Pre_columns].values\n",
    "    \n",
    "    # 计算日期范围\n",
    "    days = Pre.shape[1]\n",
    "    dates = pd.date_range(start=str(year) + '-01-01', periods=days, freq='D')\n",
    "    \n",
    "    # 添加年份信息\n",
    "    data_new['year'] = year\n",
    "    \n",
    "    # 计算极端气象指标\n",
    "    spei_df = spei(dates, Pre, Tmean)\n",
    "    CDD_df, HDD_df, GDD_df = extreme_temperature(dates, Tmax, Tmin, T_upper, T_lower)\n",
    "    \n",
    "    # 聚合8天的数据\n",
    "    data_new1 = aggre_8days(dynamic_features, dates, data_new)\n",
    "    \n",
    "    # 合并所有数据\n",
    "    data_new1 = pd.concat([CDD_df, HDD_df, GDD_df, spei_df, data_new1, data_new[soil_feature + loc_feature + Year_feature + union_feature]], axis=1)\n",
    "    \n",
    "    return data_new1\n",
    "    \n",
    "def spei(dates,Pre, Tmean):   \n",
    "    precipitation = pd.DataFrame(Pre.T, index=dates) \n",
    "    Tmean = pd.DataFrame(Tmean.T, index=dates)  \n",
    "    \n",
    "    # 转置数据框以使日期为行，特征为列\n",
    "    precipitation = precipitation.T\n",
    "    Tmean = Tmean.T\n",
    "    PET = thornthwaite(Tmean)\n",
    "    # 计算降水量与 PET 的差值\n",
    "    D = precipitation - PET\n",
    "    # 计算每隔 8 天的累积值\n",
    "    D_resampled = D.resample('8D', axis=1).sum()\n",
    "    #D_resampled = D.T.resample('8D').sum().T\n",
    "    # 计算 SPEI\n",
    "    def compute_spei(series, scale):\n",
    "        \"\"\"Calculate SPEI\"\"\"\n",
    "        # 累积值\n",
    "        cum_sum = series.cumsum()\n",
    "        # 计算均值和标准差\n",
    "        mean = cum_sum.mean()\n",
    "        std = cum_sum.std()\n",
    "        # 标准化\n",
    "        spei = (cum_sum - mean) / std\n",
    "        return spei\n",
    "    spei_values = D_resampled.apply(lambda x: compute_spei(x, scale=1), axis=1)\n",
    "    spei_df = pd.DataFrame(data = spei_values.values,columns= [f'Week{week}_SPEI' for week in range(1, 47)])\n",
    "    return spei_df\n",
    "def thornthwaite(T, lat=45):\n",
    "    \"\"\"Thornthwaite method for PET calculation\"\"\"\n",
    "    I = (T / 5.0) ** 1.514\n",
    "    a = (6.75e-7) * I**3 - (7.71e-5) * I**2 + (1.79e-2) * I + 0.49239\n",
    "    PET = 16 * ((10 * T / I) ** a)\n",
    "    return PET\n",
    "    \n",
    "def extreme_temperature(dates,Tmax,Tmin,T_upper,T_lower):\n",
    "\n",
    "    GDD = np.where(Tmax < T_lower, 0, (np.minimum(Tmax, T_upper) + np.maximum(Tmin, T_lower)) / 2 - T_lower)\n",
    "    HDD = np.maximum(Tmax, T_upper) -T_upper\n",
    "    CDD = np.minimum(Tmin, T_lower) -T_lower\n",
    "    GDD = pd.DataFrame(GDD.T, index=dates).T.resample('8D', axis=1).sum()  # 生成随机数据示例\n",
    "    HDD = pd.DataFrame(HDD.T, index=dates).T.resample('8D', axis=1).sum()  # 生成随机数据示例\n",
    "    CDD = pd.DataFrame(CDD.T, index=dates).T.resample('8D', axis=1).sum()  # 生成随机数据示例\n",
    "    CDD_df = pd.DataFrame(data = CDD.values,columns= [f'Week{week}_CDD' for week in range(1, 47)])\n",
    "    HDD_df = pd.DataFrame(data = HDD.values,columns= [f'Week{week}_HDD' for week in range(1, 47)])\n",
    "    GDD_df = pd.DataFrame(data = GDD.values,columns= [f'Week{week}_GDD' for week in range(1, 47)])\n",
    "    return CDD_df,HDD_df,GDD_df  \n",
    "\n",
    "\n",
    "def aggre_8days(dynamic_features,dates,data_new):\n",
    "\n",
    "    data_new1 = pd.DataFrame()\n",
    "    for feature in dynamic_features:\n",
    "        columns = [col for col in data_new.columns if feature in col];\n",
    "        data = data_new[columns];\n",
    "        if data.shape[1]<len(dates):\n",
    "            date_columns = pd.to_datetime(data.columns.str.replace(feature, ''), format='%Y_%m_%d')\n",
    "            data = data.T\n",
    "            data.index = date_columns\n",
    "            full_index = pd.date_range(start=dates[0], end=dates[-1])\n",
    "            data = data.reindex(full_index).sort_index()\n",
    "        else:\n",
    "            data = pd.DataFrame(data.T.values, index=dates)\n",
    "        if feature =='_Pre':\n",
    "            data = data.T.resample('8D', axis=1).sum()  #\n",
    "            data.columns = [f'Week{week}_{feature[1:]}' for week in range(1, 47)]\n",
    "        else:\n",
    "            data = data.T.resample('8D', axis=1).mean()  # 生成随机数据示例\n",
    "            data.columns = [f'Week{week}_{feature[1:]}' for week in range(1, 47)]\n",
    "        data_new1 = pd.concat([data_new1, data], axis=1)\n",
    "    return data_new1\n",
    "\n",
    "\n",
    "def extract_selected_variables(inputpath_base):\n",
    "    inpath_dates = os.path.join(inputpath_base, '01_data','05_buildmodel', '04_selectFeatures','selectFeatures.txt')\n",
    "    # 构建文件路径\n",
    "    gs_infornamtion = pd.read_csv(inpath_dates, sep='\\t', header=None)\n",
    "    gs_infornamtion.columns = ['slected_dynamic_features', 'slected_static', 'regionID']\n",
    "    gs_infornamtion['slected_dynamic_features'] = gs_infornamtion['slected_dynamic_features'].apply(ast.literal_eval)\n",
    "    gs_infornamtion['slected_static'] = gs_infornamtion['slected_static'].apply(ast.literal_eval)\n",
    "    return gs_infornamtion\n",
    "\n",
    "# 直接读取换成，可能会减少很多数据读取\n",
    "def find_weeks(inputpath_base,forecastDataList):\n",
    "    \n",
    "    # 读取所在的周数\n",
    "    file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori', 'ECMWF','CommonYear_Week.txt')\n",
    "    with open(file_path, 'r') as file:\n",
    "        week_dates = [line.strip() for line in file.readlines()]\n",
    "    result = []\n",
    "    \n",
    "    # 遍历 forecastDataList 中的每个日期\n",
    "    for date in forecastDataList:\n",
    "        # 遍历 week_dates，以便找到日期所在的 week\n",
    "        for i in range(len(week_dates) - 1):\n",
    "            # 检查日期是否在当前日期范围内（包括下边界但不包括上边界）\n",
    "            if week_dates[i] <= date < week_dates[i + 1]:\n",
    "                result.append((date, i + 1))  # week 1 对应的 index 是 0，所以 week 是 i + 1\n",
    "                break\n",
    "        # 如果日期是最后一个日期范围之外的情况（即 week46 的范围）\n",
    "        else:\n",
    "            if date >= week_dates[-1]:\n",
    "                result.append((date, len(week_dates)))  # 最后一周 week46\n",
    "    result = {date: week for date, week in result}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6758cd69-d282-4094-befd-86062c6d55f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: F:\\SCI\\SCI9_1\\01_code\\02_Wheat\\06_India\n",
      "当前文件夹名字: 06_India\n",
      "上一级文件夹名字: 02_Wheat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta,date\n",
    "root_directory = os.getcwd()[0:3]\n",
    "sys.path.append(root_directory+'SCI\\\\SCI9_1\\\\01_code')\n",
    "sys.path.append(r'C:\\ProgramData\\anaconda3\\Lib\\site-packages') \n",
    "sys.path.append(r'C:\\Users\\DELL\\.conda\\envs\\myenv\\Lib\\site-packages') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ast\n",
    "from fastdtw import fastdtw\n",
    " \n",
    "# 获取当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(\"当前工作目录:\", current_directory)\n",
    " \n",
    "# 获取当前文件夹的名字\n",
    "current_folder_name = os.path.basename(current_directory)\n",
    "print(\"当前文件夹名字:\", current_folder_name)\n",
    " \n",
    "# 获取上一级文件夹的名字\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "parent_folder_name = os.path.basename(parent_directory)\n",
    "print(\"上一级文件夹名字:\", parent_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bc4ff92-9c24-483e-90d0-2ef82da1719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改的变量\n",
    "crop = parent_folder_name;countryID =current_folder_name;variable = 'mx2t6';\n",
    "region ='I';\n",
    "country = countryID.split('_')[1]\n",
    "##############地区区域#############################################\n",
    "inpath_dates_other = root_directory + '\\\\SCI\\\\SCI9_1\\\\02_data\\\\'+crop+'\\\\'+countryID+'\\\\'+'01_data'+'\\\\'+'07_Information'\n",
    "other_infornamtion = pd.read_csv(os.path.join(inpath_dates_other,'information.txt'), sep=' ', header=None)\n",
    "startyear,endyear,shp_name = other_infornamtion.iloc[0,0],other_infornamtion.iloc[0,1],other_infornamtion.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0368723a-8b53-4325-9be4-02138b440b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori',institution,'CommonYear_Week.txt')\n",
    "inpath_dates = os.path.join(inputpath_base, '01_data', '05_buildmodel', '02_extractdates', 'gs_three_periods.txt')\n",
    "# 从文件中读取行并去除两端空白字符\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# 从另一个文件中读取起始点和收获点\n",
    "file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori',institution,'CommonYear_Week.txt')\n",
    "inpath_dates = os.path.join(inputpath_base, '01_data', '05_buildmodel', '02_extractdates', 'gs_three_periods.txt')\n",
    "# 从文件中读取行并去除两端空白字符\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# 从另一个文件中读取起始点和收获点\n",
    "gs_infornamtion = pd.read_csv(inpath_dates, sep='\\t', header=None)\n",
    "gs_infornamtion.columns = ['start_point', 'peak', 'harvest_point','VI_select2','regions']\n",
    "harvest_point = gs_infornamtion[gs_infornamtion['regions']==region]['harvest_point'].values[0]\n",
    "start_point = gs_infornamtion[gs_infornamtion['regions']==region]['start_point'].values[0]\n",
    "VI_select2 = gs_infornamtion[gs_infornamtion['regions']==region]['VI_select2'].values[0]\n",
    "\n",
    "# 将收获点和起始点的字符串转换为整数\n",
    "harvest_point = int(harvest_point) # 汇聚为8天是往后汇聚的，比如01-01，是指的01-01到01-08的汇聚指标\n",
    "start_point = int(start_point)\n",
    "\n",
    "# 根据收获点和起始点的索引，从lines中取得对应的日期\n",
    "if harvest_point ==46:\n",
    "    harvest_date_doy = '-'+'12-31'\n",
    "else:\n",
    "    harvest_date_doy = '-' + lines[harvest_point]\n",
    "start_date_doy = '-' + lines[start_point]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01bbf35b-3792-4f07-a6b4-27d49c03cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvest_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4cca4a9-3a44-41d3-9c78-0a558218b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['I']\n",
    "Forecastyears = {'I': endyear}\n",
    "# 按照作物定义温度阈值\n",
    "if crop == '02_Wheat':\n",
    "    T_upper = 34\n",
    "    T_lower = 0\n",
    "elif crop == '01_Maize':  # 修正了拼写错误\n",
    "    T_upper = 30\n",
    "    T_lower = 8\n",
    "elif crop == '03_Rice':\n",
    "    T_upper = 35\n",
    "    T_lower = 8    \n",
    "else:\n",
    "    T_upper = 30\n",
    "    T_lower = 10\n",
    "    \n",
    "\n",
    "\n",
    "VIs =  ['_KNDVI' ,'_EVI','_NDVI']\n",
    "Cilmate = ['_Pre' ,'_Tmin' ,'_Solar','_Tmean','_Tmax']\n",
    "Climate_Exogenous  = ['_CDD' ,'_HDD' ,'_GDD','_VPD','_wind_speed','_SPEI'] #'_VPD','_wind_speed',\n",
    "soil_feature = [ 'SAND','AWC', 'SILT','ORG_CARBON',  'TOTAL_N', 'PH_WATER',  'CEC_SOIL', 'CLAY']\n",
    "loc_feature = ['elevation', 'lat', 'lon']\n",
    "Year_feature = ['year'];union_feature = ['idJoin'];\n",
    "dynamic_features = [ '_KNDVI' ,'_EVI','_NDVI','_Pre' ,'_Tmin' ,'_Solar','_Tmean','_VPD', '_wind_speed' ,'_Tmax']\n",
    "inputpath_base = root_directory + '\\\\SCI\\\\SCI9_1\\\\02_data\\\\'+crop+'\\\\'+countryID+'\\\\'\n",
    "\n",
    "forecast_days = 46;country =countryID.split('_')[1]\n",
    "yield_type = 'actual_yield';origen ='ECMWF';institution = 'ECMWF';\n",
    "ECMWF_path = os.path.join(inputpath_base,'02_S2S')\n",
    "S2S_data_path = os.path.join(ECMWF_path,'02_Reforecast', origen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe55c71-7956-42dc-a2f1-2a739e2f5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indiagee_up_load_winter.shp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b6f085-c21d-4afc-95c7-b04f00ffee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_all = os.path.join(inputpath_base,'01_data','02_shp',shp_name)\n",
    "gdf_all = gpd.read_file(shp_all)\n",
    "\n",
    "\n",
    "'''\n",
    "#shp_name = 'Chinagee_up_load.shp'\n",
    "#shp_all = os.path.join(inputpath_base,'01_data','02_shp',shp_name)\n",
    "# 输出样本变量tif，为后面的pointid读取做准备\n",
    "gdf_all = gpd.read_file(shp_all)\n",
    "if 'region' not in gdf_all.columns:\n",
    "    gdf_all['region'] ='I'\n",
    "else:\n",
    "    pass\n",
    "'''\n",
    "\n",
    "for region in regions:\n",
    "    if 'region' not in gdf_all.columns:\n",
    "        gdf_all['region'] ='I'\n",
    "        filtered_data_ori_upload = gdf_all\n",
    "    else:\n",
    "        filtered_data_ori_upload = gdf_all# [gdf_all['region']==region] # [ToDo]核查是否有分区\n",
    "    Forecastyear =  Forecastyears[region];years =str(Forecastyear)+'_'+str(Forecastyear);\n",
    "    forecastDataList = os.listdir(os.path.join(inputpath_base,'02_S2S','02_Reforecast','ECMWF',region))\n",
    "    filename = institution+\"_\"+variable+\"_\"+country+\"_cf_forecasttimefcst_\"+years+\".grib\"\n",
    "    file = os.path.join(inputpath_base, '02_S2S','02_Reforecast','ECMWF',region,forecastDataList[0],filename)\n",
    "    ds = xr.open_dataset(file, engine='cfgrib')\n",
    "    d2m_data = ds.isel(step=0)['mx2t6']\n",
    "    d2m_data.rio.write_crs(\"epsg:4326\", inplace=True)  # 假设数据是WGS84坐标系统\n",
    "    os.makedirs(os.path.join(inputpath_base,'02_S2S','08_Tif',region), exist_ok=True)\n",
    "    output_path = os.path.join(inputpath_base,'02_S2S','08_Tif',region,region+'_'+variable+'_data.tif')\n",
    "    d2m_data.rio.to_raster(output_path)\n",
    "    # filtered_data_ori_upload = gdf_all[gdf_all['region']==region]\n",
    "    filtered_data_ori_upload.to_file(os.path.join(inputpath_base, '01_data','02_shp',country+'_'+region+'.shp'), driver='ESRI Shapefile')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f986d87-5c8f-435f-aea9-23e926069f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;mx2t6&#x27; (latitude: 18, longitude: 23)&gt;\n",
       "[414 values with dtype=float32]\n",
       "Coordinates:\n",
       "    number             int32 ...\n",
       "    time               datetime64[ns] ...\n",
       "    step               timedelta64[ns] 06:00:00\n",
       "    heightAboveGround  float64 ...\n",
       "  * latitude           (latitude) float64 36.4 34.9 33.4 31.9 ... 13.9 12.4 10.9\n",
       "  * longitude          (longitude) float64 66.1 67.6 69.1 ... 96.1 97.6 99.1\n",
       "    valid_time         datetime64[ns] ...\n",
       "    spatial_ref        int32 0\n",
       "Attributes: (12/30)\n",
       "    GRIB_paramId:                             121\n",
       "    GRIB_dataType:                            cf\n",
       "    GRIB_numberOfPoints:                      414\n",
       "    GRIB_typeOfLevel:                         heightAboveGround\n",
       "    GRIB_stepUnits:                           1\n",
       "    GRIB_stepType:                            max\n",
       "    ...                                       ...\n",
       "    GRIB_shortName:                           mx2t6\n",
       "    GRIB_totalNumber:                         11\n",
       "    GRIB_units:                               K\n",
       "    long_name:                                Maximum temperature at 2 metres...\n",
       "    units:                                    K\n",
       "    standard_name:                            air_temperature</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'mx2t6'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 18</li><li><span class='xr-has-index'>longitude</span>: 23</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-750d63ba-25b2-4ded-a380-d4776bff9226' class='xr-array-in' type='checkbox' checked><label for='section-750d63ba-25b2-4ded-a380-d4776bff9226' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>...</span></div><div class='xr-array-data'><pre>[414 values with dtype=float32]</pre></div></div></li><li class='xr-section-item'><input id='section-74769b6e-adf5-4663-80c2-8c0f3ad7117d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-74769b6e-adf5-4663-80c2-8c0f3ad7117d' class='xr-section-summary' >Coordinates: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>number</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2f054d89-5268-412e-9646-d28a680d430a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2f054d89-5268-412e-9646-d28a680d430a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f0dece3c-537f-42ad-bd2f-7c6f9e8d8845' class='xr-var-data-in' type='checkbox'><label for='data-f0dece3c-537f-42ad-bd2f-7c6f9e8d8845' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>ensemble member numerical id</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>standard_name :</span></dt><dd>realization</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=int32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b65023e8-2ee2-4b14-835f-e1906058fcac' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b65023e8-2ee2-4b14-835f-e1906058fcac' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e37ef396-9e6c-4bc7-b99a-492a1ad2f7ff' class='xr-var-data-in' type='checkbox'><label for='data-e37ef396-9e6c-4bc7-b99a-492a1ad2f7ff' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>initial time of forecast</dd><dt><span>standard_name :</span></dt><dd>forecast_reference_time</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=datetime64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>step</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>timedelta64[ns]</div><div class='xr-var-preview xr-preview'>06:00:00</div><input id='attrs-001a7efa-29d4-4e32-b3cd-7435b380b244' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-001a7efa-29d4-4e32-b3cd-7435b380b244' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6cef04fc-9179-41bc-9606-465f02513db1' class='xr-var-data-in' type='checkbox'><label for='data-6cef04fc-9179-41bc-9606-465f02513db1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time since forecast_reference_time</dd><dt><span>standard_name :</span></dt><dd>forecast_period</dd></dl></div><div class='xr-var-data'><pre>array(21600000000000, dtype=&#x27;timedelta64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>heightAboveGround</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b9c63693-f28c-4119-93ca-a59f1511852e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b9c63693-f28c-4119-93ca-a59f1511852e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4533994b-cd21-42fc-9f2e-1a2711b03be7' class='xr-var-data-in' type='checkbox'><label for='data-4533994b-cd21-42fc-9f2e-1a2711b03be7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>height above the surface</dd><dt><span>units :</span></dt><dd>m</dd><dt><span>positive :</span></dt><dd>up</dd><dt><span>standard_name :</span></dt><dd>height</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>36.4 34.9 33.4 ... 13.9 12.4 10.9</div><input id='attrs-198856f7-8865-4e5e-ad82-08c10d827737' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-198856f7-8865-4e5e-ad82-08c10d827737' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3c01eaf0-ba41-4fc8-822d-5ac58313a2b4' class='xr-var-data-in' type='checkbox'><label for='data-3c01eaf0-ba41-4fc8-822d-5ac58313a2b4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>stored_direction :</span></dt><dd>decreasing</dd></dl></div><div class='xr-var-data'><pre>array([36.4, 34.9, 33.4, 31.9, 30.4, 28.9, 27.4, 25.9, 24.4, 22.9, 21.4, 19.9,\n",
       "       18.4, 16.9, 15.4, 13.9, 12.4, 10.9])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>66.1 67.6 69.1 ... 96.1 97.6 99.1</div><input id='attrs-1032db25-9998-4cb8-aed1-461ce8b5286d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1032db25-9998-4cb8-aed1-461ce8b5286d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-14a30586-8a76-4278-90a7-8ce578ac72ca' class='xr-var-data-in' type='checkbox'><label for='data-14a30586-8a76-4278-90a7-8ce578ac72ca' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([66.1, 67.6, 69.1, 70.6, 72.1, 73.6, 75.1, 76.6, 78.1, 79.6, 81.1, 82.6,\n",
       "       84.1, 85.6, 87.1, 88.6, 90.1, 91.6, 93.1, 94.6, 96.1, 97.6, 99.1])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>valid_time</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-58baac7b-f1b5-4406-8829-17f2debcca15' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-58baac7b-f1b5-4406-8829-17f2debcca15' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-724d040e-5dc9-4e99-8428-bd936f38d453' class='xr-var-data-in' type='checkbox'><label for='data-724d040e-5dc9-4e99-8428-bd936f38d453' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=datetime64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-e4cb0340-bd57-4d67-9abe-b1a83d533c96' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e4cb0340-bd57-4d67-9abe-b1a83d533c96' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b3dcc5c3-273d-4e45-af73-d74c9c80e6b5' class='xr-var-data-in' type='checkbox'><label for='data-b3dcc5c3-273d-4e45-af73-d74c9c80e6b5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs_wkt :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>spatial_ref :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd></dl></div><div class='xr-var-data'><pre>array(0)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-131ca5f5-04af-4832-90a5-fd8da084d991' class='xr-section-summary-in' type='checkbox'  ><label for='section-131ca5f5-04af-4832-90a5-fd8da084d991' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-4fdb9d04-222d-4856-b240-c57f63affc37' class='xr-index-data-in' type='checkbox'/><label for='index-4fdb9d04-222d-4856-b240-c57f63affc37' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([              36.4,               34.9,               33.4,\n",
       "                     31.9,               30.4,               28.9,\n",
       "                     27.4,               25.9,               24.4,\n",
       "                     22.9,               21.4,               19.9,\n",
       "                     18.4,               16.9, 15.399999999999999,\n",
       "       13.899999999999999, 12.399999999999999,               10.9],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-74316121-07d6-419f-ad86-072f4ecfd7c2' class='xr-index-data-in' type='checkbox'/><label for='index-74316121-07d6-419f-ad86-072f4ecfd7c2' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([66.1, 67.6, 69.1, 70.6, 72.1, 73.6, 75.1, 76.6, 78.1, 79.6, 81.1, 82.6,\n",
       "       84.1, 85.6, 87.1, 88.6, 90.1, 91.6, 93.1, 94.6, 96.1, 97.6, 99.1],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7f1a8111-85c3-4d47-be2f-4a1d72d95e42' class='xr-section-summary-in' type='checkbox'  ><label for='section-7f1a8111-85c3-4d47-be2f-4a1d72d95e42' class='xr-section-summary' >Attributes: <span>(30)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>GRIB_paramId :</span></dt><dd>121</dd><dt><span>GRIB_dataType :</span></dt><dd>cf</dd><dt><span>GRIB_numberOfPoints :</span></dt><dd>414</dd><dt><span>GRIB_typeOfLevel :</span></dt><dd>heightAboveGround</dd><dt><span>GRIB_stepUnits :</span></dt><dd>1</dd><dt><span>GRIB_stepType :</span></dt><dd>max</dd><dt><span>GRIB_gridType :</span></dt><dd>regular_ll</dd><dt><span>GRIB_NV :</span></dt><dd>0</dd><dt><span>GRIB_Nx :</span></dt><dd>23</dd><dt><span>GRIB_Ny :</span></dt><dd>18</dd><dt><span>GRIB_cfName :</span></dt><dd>air_temperature</dd><dt><span>GRIB_cfVarName :</span></dt><dd>mx2t6</dd><dt><span>GRIB_gridDefinitionDescription :</span></dt><dd>Latitude/longitude</dd><dt><span>GRIB_iDirectionIncrementInDegrees :</span></dt><dd>1.5</dd><dt><span>GRIB_iScansNegatively :</span></dt><dd>0</dd><dt><span>GRIB_jDirectionIncrementInDegrees :</span></dt><dd>1.5</dd><dt><span>GRIB_jPointsAreConsecutive :</span></dt><dd>0</dd><dt><span>GRIB_jScansPositively :</span></dt><dd>0</dd><dt><span>GRIB_latitudeOfFirstGridPointInDegrees :</span></dt><dd>36.4</dd><dt><span>GRIB_latitudeOfLastGridPointInDegrees :</span></dt><dd>10.9</dd><dt><span>GRIB_longitudeOfFirstGridPointInDegrees :</span></dt><dd>66.1</dd><dt><span>GRIB_longitudeOfLastGridPointInDegrees :</span></dt><dd>99.1</dd><dt><span>GRIB_missingValue :</span></dt><dd>3.4028234663852886e+38</dd><dt><span>GRIB_name :</span></dt><dd>Maximum temperature at 2 metres in the last 6 hours</dd><dt><span>GRIB_shortName :</span></dt><dd>mx2t6</dd><dt><span>GRIB_totalNumber :</span></dt><dd>11</dd><dt><span>GRIB_units :</span></dt><dd>K</dd><dt><span>long_name :</span></dt><dd>Maximum temperature at 2 metres in the last 6 hours</dd><dt><span>units :</span></dt><dd>K</dd><dt><span>standard_name :</span></dt><dd>air_temperature</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'mx2t6' (latitude: 18, longitude: 23)>\n",
       "[414 values with dtype=float32]\n",
       "Coordinates:\n",
       "    number             int32 ...\n",
       "    time               datetime64[ns] ...\n",
       "    step               timedelta64[ns] 06:00:00\n",
       "    heightAboveGround  float64 ...\n",
       "  * latitude           (latitude) float64 36.4 34.9 33.4 31.9 ... 13.9 12.4 10.9\n",
       "  * longitude          (longitude) float64 66.1 67.6 69.1 ... 96.1 97.6 99.1\n",
       "    valid_time         datetime64[ns] ...\n",
       "    spatial_ref        int32 0\n",
       "Attributes: (12/30)\n",
       "    GRIB_paramId:                             121\n",
       "    GRIB_dataType:                            cf\n",
       "    GRIB_numberOfPoints:                      414\n",
       "    GRIB_typeOfLevel:                         heightAboveGround\n",
       "    GRIB_stepUnits:                           1\n",
       "    GRIB_stepType:                            max\n",
       "    ...                                       ...\n",
       "    GRIB_shortName:                           mx2t6\n",
       "    GRIB_totalNumber:                         11\n",
       "    GRIB_units:                               K\n",
       "    long_name:                                Maximum temperature at 2 metres...\n",
       "    units:                                    K\n",
       "    standard_name:                            air_temperature"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [TODO] 确认是否已经准备好所有区的dataJoin#########确认好后继续往下处理\n",
    "d2m_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "546f19e0-ff2c-4a14-bae8-6fcafb337a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO##########################运行此代码前需要准备dataJoin_I##############################################\n",
    "# 输出到03_outputData\n",
    "\n",
    "# 预报数据处理\n",
    "for region in regions:\n",
    "    Forecastyear = Forecastyears[region];years =str(Forecastyear)+'_'+str(Forecastyear);\n",
    "    _, _, _, harvest_date_doy, _ = extract_dates(inputpath_base,institution,region)\n",
    "    dataJoin1 =  pd.read_csv(os.path.join(inputpath_base, '02_S2S', '01_dataori',institution, f'dataJoin_{region}.csv'))\n",
    "    forecastDataList = os.listdir(os.path.join(inputpath_base,'02_S2S','02_Reforecast','ECMWF',region))\n",
    "    # 方法2 适用于大国家 20241104，一个行政区找到一个格点\n",
    "    # 一共11个集合模型，分模式输出\n",
    "    for ii in forecastDataList:# 注意修改这里改成批量算法 #[0:1]\n",
    "        ###########################读取收获日期###################################\n",
    "        pathto = os.path.join(ECMWF_path,'02_Reforecast', origen, region,ii)\n",
    "        outpath = os.path.join(ECMWF_path,'03_outputData', origen, region,ii)\n",
    "        create_directory(outpath)\n",
    "        ds_pf_mx2t6, ds_pf_mn2t6, ds_pf_2t, ds_pf_tp, ds_df_wind_speed, ds_pf_vpd, ds_pf_ssr = read_pf_data(pathto, origen, country, years)\n",
    "        ds_cf_mx2t6, ds_cf_mn2t6, ds_cf_2t, ds_cf_tp, ds_cf_wind_speed, ds_cf_vpd, ds_cf_ssr =read_cf_data(pathto, origen, country, years)\n",
    "        \n",
    "        ds_cf_mn2t6, ds_cf_mx2t6 = process_temperature_data(ds_cf_mn2t6, ds_cf_mx2t6)\n",
    "        ds_pf_mn2t6, ds_pf_mx2t6 = process_temperature_data(ds_pf_mn2t6, ds_pf_mx2t6)\n",
    "        ds_pf_mx2t6 =ds_pf_mx2t6[0];ds_pf_mn2t6 =ds_pf_mn2t6[0];\n",
    "        ds_cf_mx2t6 =ds_cf_mx2t6[0];ds_cf_mn2t6 =ds_cf_mn2t6[0];\n",
    "        ds_pf_mn2t6 = np.transpose(ds_pf_mn2t6, (1, 0, 2, 3))\n",
    "        ds_pf_mx2t6 = np.transpose(ds_pf_mx2t6, (1, 0, 2, 3))\n",
    "        ds_pf_2t, ds_pf_tp, ds_pf_ssr, ds_df_wind_speed, ds_pf_vpd = process_df_arrays(ds_pf_2t, ds_pf_tp, ds_pf_ssr, ds_df_wind_speed, ds_pf_vpd)\n",
    "        ds_cf_2t, ds_cf_tp, ds_cf_ssr, ds_cf_wind_speed, ds_cf_vpd = process_cf_arrays(ds_cf_2t, ds_cf_tp, ds_cf_ssr, ds_cf_wind_speed, ds_cf_vpd)\n",
    "        \n",
    "        # pf中的10个模型输出\n",
    "        number =10\n",
    "        for ID in range(0,number):\n",
    "            year = Forecastyear\n",
    "            date_harvest = str(year)+harvest_date_doy\n",
    "            date_harvest = pd.Timestamp(date_harvest).strftime('%Y%m%d')\n",
    "            time_value = str(year)+'-'+ii  # 预报第一天的日期\n",
    "            time_value1 = pd.Timestamp(time_value).strftime('%Y%m%d') # 预报第一天的日期\n",
    "            days_between = calculate_days_between(time_value1, date_harvest)# 只提取用于建模的数据\n",
    "            steps_total = min(days_between+1,forecast_days)\n",
    "            features = ['Tmax', 'Tmin', 'Tmean', 'Pre', 'wind_speed', 'VPD', 'Solar']\n",
    "            data_every_number = dataJoin1[['idJoin','pointid']]\n",
    "            for feature, selected in zip(features, [ds_pf_mn2t6, ds_pf_mx2t6, ds_pf_2t, ds_pf_tp, ds_df_wind_speed, ds_pf_vpd,ds_pf_ssr]):\n",
    "                for step in range(0,steps_total):  #只提取用于建模的数据，但是多提取了一天，对后面没影响，不会用到那一天的数据\n",
    "                    time = (pd.Timestamp(time_value1) + pd.Timedelta(days=step)).strftime('%Y%m%d') #当前预报时间，第一天，第二天以此类推的日期\n",
    "                    data_sel = selected[ID,step,:].flatten()\n",
    "                    data_every_number[time + '_' + feature] = data_every_number['pointid'].apply(lambda x: data_sel[x-1])\n",
    "                    #按照dataJoin中的pointId指示的位置链接数据，生成一组新的tmax列添加到原有pointId，成为新的data1data1\n",
    "            data_every_number.to_csv(os.path.join(outpath, 'number'+str(ID) + '.csv'), index=False)\n",
    "            \n",
    "        # 第cf模型输出\n",
    "        number =10\n",
    "        data_every_number = dataJoin1[['idJoin','pointid']]\n",
    "        for feature, selected in zip(features, [ds_cf_mn2t6, ds_cf_mx2t6, ds_cf_2t, ds_cf_tp, ds_cf_wind_speed, ds_cf_vpd,ds_cf_ssr]):\n",
    "            for step in range(0,steps_total):  #只提取用于建模的数据，但是多提取了一天，对后面没影响，不会用到那一天的数据\n",
    "                time = (pd.Timestamp(time_value1) + pd.Timedelta(days=step)).strftime('%Y%m%d') #当前预报时间，第一天，第二天以此类推的日期\n",
    "                data_sel = selected[step,:].flatten()\n",
    "                data_every_number[time + '_' + feature] = data_every_number['pointid'].apply(lambda x: data_sel[x-1])\n",
    "        data_every_number.to_csv(os.path.join(outpath, 'number'+str(number) + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a82ce4-4702-47f7-9924-8c0553bd803f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac281c7e-496d-4918-8044-7d58d2d6a229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fa432d6-21b3-4b14-8844-0f36b2e01ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 核对pre_name的格式是否正确\n",
    "# 对于预报年，输出预报日期后的预报数据的集合和历史30年的周尺度集合，并汇聚到0-46周\n",
    "# 读取原始预报年和提前预报的日期\n",
    "\n",
    "# 直接读取换成，可能会减少很多数据读取\n",
    "\n",
    "#[20250317] simple_week  的定义丢失了\n",
    "\n",
    "numbers=11\n",
    "for region in regions:\n",
    "    pre_name ='WinterWheat'+'_'+countryID[3:]+'I_' # 需要核对是否是符合这种标识\n",
    "    '''\n",
    "    if region == 'I':\n",
    "        pre_name = 'EarlyRice_daily'+country+region+'_'\n",
    "    elif region == 'II':\n",
    "        pre_name = 'LateRice_daily'+country+region+'_'\n",
    "    else:\n",
    "        pre_name = 'SingleRice_daily'+country+region+'_'\n",
    "    '''\n",
    "    Forecastyear = Forecastyears[region]\n",
    "    years = range(startyear,Forecastyear) # 历史年份寻找相似KNDVI可以用\n",
    "    data_ori = pd.read_csv(os.path.join(inputpath_base, '01_data', '04_GEEdownloadData','01_DailyData',pre_name+str(Forecastyear))+'.csv')\n",
    "    data_ori.set_index('idJoin', inplace=True)\n",
    "    forecastDataList = os.listdir(os.path.join(inputpath_base,'02_S2S','02_Reforecast','ECMWF',region))\n",
    "    \n",
    "    # 读取筛选的变量，用于后续变量筛选\n",
    "    Forecastyear = Forecastyears[region]\n",
    "    SelFeature_infornamtion = extract_selected_variables(inputpath_base)\n",
    "    TimeFeatures_sel, Static_sel, regionID = SelFeature_infornamtion[SelFeature_infornamtion['regionID'] == region].iloc[0]\n",
    "    \n",
    "    # 实际建模的周数\n",
    "    inpath_dates = os.path.join(inputpath_base, '01_data','05_buildmodel', '02_extractdates','gs_three_periods.txt')\n",
    "    gs_infornamtion = pd.read_csv(inpath_dates, delim_whitespace=True, header=None)\n",
    "    gs_infornamtion.columns = ['start_point', 'peak', 'harvest_point', 'VI_select2','regionID']\n",
    "    start_point, peak, harvest_point, VI_select2, region = gs_infornamtion[gs_infornamtion['regionID'] == region].iloc[0]\n",
    "    \n",
    "    # 数据读取和指数的筛选\n",
    "    data_ori_all = pd.read_csv(os.path.join(inputpath_base, '01_data','05_buildmodel','01_weekdata',region+'_allweekYielddata_VIs.csv'))\n",
    "    Static_sel= [col for col in Static_sel if 'year.1' not in col] \n",
    "    TimeFeatures_sel_all= [col for col in data_ori_all.columns if any(feature in col for feature in TimeFeatures_sel)]\n",
    "    TimeFeatures_sel_all= [col for col in TimeFeatures_sel_all if 'Previous_Yield' not in col] # 注意前一年的产量会因为pre降雨而被筛选到，仔细确认\n",
    "    filtered_columns_all = TimeFeatures_sel_all+Static_sel\n",
    "    data_ori_all = data_ori_all[filtered_columns_all+['idJoin','Yield']] # 筛选选择的变量进入后续分析\n",
    "\n",
    "\n",
    "        # 筛选VI进行后续的识别\n",
    "    filtered_columns_VI = [col for col in data_ori_all.columns if VI_select2 in col]\n",
    "    data_S2S_VI = data_ori_all[filtered_columns_VI + ['year','idJoin']]\n",
    "    data_S2S_VI_mean = data_S2S_VI[filtered_columns_VI + ['year']].groupby('year').mean()\n",
    "    \n",
    "    S2SWeekList = ['leadweek_'+str(week) for week in range(1,6+1)] # 提前1年即46周\n",
    "    data_ori_current = data_ori_all[data_ori_all['year']==Forecastyear]\n",
    "\n",
    "\n",
    "\n",
    "    dataweeks = find_weeks(inputpath_base,forecastDataList)\n",
    "    \n",
    "    unique_values = {}\n",
    "    for key, value in dataweeks.items():\n",
    "        if value not in unique_values.values():\n",
    "            unique_values[key] = value\n",
    "    \n",
    "    simple_week = {key: f\"leadweek_{len(dataweeks) - idx}\" for idx, key in enumerate(unique_values.keys())}    \n",
    "    for ii, leadweek in simple_week.items():# 注意修改这里改成批量算法 #[0:1]\n",
    "        # for number循环\n",
    "        for number in range(0,numbers):\n",
    "            data_S2S_new = data_ori.copy()\n",
    "            inputpath = os.path.join(ECMWF_path,'03_outputData', institution, region,ii)\n",
    "            data_S2S = pd.read_csv(os.path.join(inputpath,'number'+ str(number) + '.csv'))\n",
    "            data_S2S.set_index('idJoin', inplace=True)\n",
    "            common_columns = data_S2S.columns.intersection(data_S2S_new.columns)\n",
    "            data_S2S_new[common_columns] = data_S2S[common_columns] \n",
    "           # data_S2S_new.to_csv(os.path.join(outpath, str(year) + '.csv'))\n",
    "            data_S2S_new = process_climate_data(data_S2S_new.reset_index(), Forecastyear, T_upper, T_lower, dynamic_features, soil_feature, loc_feature, Year_feature, union_feature)\n",
    "            #data_S2S_new.to_csv(os.path.join(outpath, 'number'+str(number) + '.csv'),index=False)\n",
    "\n",
    "            data_S2S_new_update = data_ori_current.copy()\n",
    "            #data_his_new = data_his_new.merge(data_ori_current[filtered_columns_VI+Static_sel+['idJoin','Yield']],on='idJoin',how='inner')# 将VI，静态变量和Y update上面去，数据种类预期保持一致\n",
    "            # 同样的进行变量类别的筛选,保证只有被筛选的变量才会在里面\n",
    "            data_S2S_new['year'] = Forecastyear \n",
    "            # data_his_new = data_his_new[filtered_columns_all+['idJoin']]      \n",
    "\n",
    "            ############################################## 找最相似的植被指数填充 ############################################################################\n",
    "            week_forecast = harvest_point+1-int(leadweek[9:])\n",
    "            # 前一年到后一年，保证一年的实际，因为不能只用当年，可能会没有实际年份；当前年到目前年\n",
    "            forecast_weeklist1 = range(week_forecast, harvest_point + 1)\n",
    "            forecast_weeklist = [f'Week{week}{VI_select2}' for week in forecast_weeklist1]# 预报当前周到收获的日子week_forecast是没有的\n",
    "            V1= [f'Week{week}{VI_select2}' for week in range(1, week_forecast)];\n",
    "            V2= [f'Week{week}{VI_select2}' for week in range(week_forecast, 46+1)];\n",
    "    \n",
    "            current_S2S_VI_before =pd.concat([data_S2S_VI_mean.loc[Forecastyear][V1], data_S2S_VI_mean.loc[Forecastyear-1][V2]])\n",
    "            dtw_distances = {}\n",
    "            for year1 in range(startyear+1,Forecastyear):# 不会取到Forecastyear年\n",
    "                other_S2S_VI_before = pd.concat([data_S2S_VI_mean.loc[year1][V1], data_S2S_VI_mean.loc[year1-1][V2]])\n",
    "                distance, path = fastdtw(current_S2S_VI_before, other_S2S_VI_before)# 预报当前周到收获的日子\n",
    "                dtw_distances[year1] = distance\n",
    "            most_similar_by_dtw = min(dtw_distances, key=dtw_distances.get) # 找到2016年\n",
    "            model_VI_replace = forecast_weeklist\n",
    "                \n",
    "        \n",
    "                \n",
    "            data_S2S_VI_forecast2 = data_S2S_VI[data_S2S_VI['year'] == most_similar_by_dtw][model_VI_replace+['idJoin']]# 只需要建模的数据\n",
    "            data_S2S_new_update = data_S2S_new_update.drop(model_VI_replace,axis=1) # 删除原有的预报日期对应的，不预报还是保留\n",
    "            data_S2S_new_update = data_S2S_new_update.merge(data_S2S_VI_forecast2,on='idJoin',how='inner')\n",
    "\n",
    "            ############################################## S2S替换原始数据的需要预报的周数 ###################################################################\n",
    "            # for 循环找到需要替换的变量,替换是his来替换原始\n",
    "            update_climate = []\n",
    "            for feature in [feature for feature in TimeFeatures_sel if feature != VI_select2[1:]]: # 除了植被指数的所选气象数据\n",
    "                update_climate += [f'Week{week}_{feature}' for week in forecast_weeklist1]\n",
    "            data_S2S_new_update.set_index('idJoin', inplace=True)\n",
    "            data_S2S_new.set_index('idJoin', inplace=True)\n",
    "            data_S2S_new_update[update_climate] = data_S2S_new[update_climate] # 替换是S2S来替换原始，\n",
    "\n",
    "            ############################################## 筛选生育期的变量 ############################################################################\n",
    "            weeks = []\n",
    "            # 判断是否跨年\n",
    "            if start_point < harvest_point:  # 不跨年\n",
    "                for feature in TimeFeatures_sel:\n",
    "                    # 使用列表生成器生成周和特征的组合\n",
    "                    weeks += [f'Week{week}_{feature}' for week in range(start_point, harvest_point + 1)]\n",
    "            else:  # 跨年\n",
    "                for feature in TimeFeatures_sel:\n",
    "                    # 合并两段范围并生成周和特征的组合\n",
    "                    weeks += [f'Week{week}_{feature}' for week in list(range(start_point, 47)) + list(range(1, harvest_point + 1))]\n",
    "            gs_features = weeks + Static_sel+['Yield']+['idJoin']\n",
    "            data_S2S_new_update.reset_index('idJoin', inplace=True)            \n",
    "            data_S2S_new_update = data_S2S_new_update[gs_features]\n",
    "            \n",
    "            ##############################################输出 ############################################################################\n",
    "            S2S_outputpath = os.path.join(inputpath_base,'02_S2S','05_WeekData','01_S2S','VI_Like',region,leadweek)\n",
    "            os.makedirs(S2S_outputpath,exist_ok=True)\n",
    "            data_S2S_new_update.to_csv(os.path.join(S2S_outputpath,'number'+ str(number) + '.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd0ae0-6dde-467a-ae02-d221e2c1377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5907670c-77fc-4964-a811-f489b74bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################['number','Leadweek','hist_year','climate','distance']计算相似度#######################\n",
    "############################依据相似年补充后面没有预报数据的、KNDVI除外#######################################\n",
    "#########################相似年是计算的所有气象因子##############################################\n",
    "gs_infornamtion = pd.read_csv(inpath_dates, delim_whitespace=True, header=None)\n",
    "gs_infornamtion.columns = ['start_point', 'peak', 'harvest_point', 'VI_select2','regionID']\n",
    "start_point, peak, harvest_point, VI_select2, region = gs_infornamtion[gs_infornamtion['regionID'] == region].iloc[0]\n",
    "if VI_select2[1:] in TimeFeatures_sel:\n",
    "    TimeFeatures_sel.remove(VI_select2[1:])\n",
    "hist_start_year = Forecastyear-30;hist_end_year = Forecastyear-1;\n",
    "data = []\n",
    "for year_hist in range(hist_start_year,hist_end_year+1):\n",
    "    hist_outputpath1 = os.path.join(inputpath_base,'02_S2S','05_WeekData','02_hist',region)\n",
    "    data_his_new_update = pd.read_csv(os.path.join(hist_outputpath1,'hist_'+str(year_hist)+'.csv'))\n",
    "    dataweeks = find_weeks(inputpath_base,forecastDataList)\n",
    "    \n",
    "    unique_values = {}\n",
    "    for key, value in dataweeks.items():\n",
    "        if value not in unique_values.values():\n",
    "            unique_values[key] = value\n",
    "    \n",
    "    simple_week = {key: f\"leadweek_{len(dataweeks) - idx}\" for idx, key in enumerate(unique_values.keys())}  \n",
    "    \n",
    "    for _, S2S_leadweek in simple_week.items():# 注意修改这里改成批量算法 #[0:1]\n",
    "        if int(S2S_leadweek[9:])-6<=0:\n",
    "            pass # 不需要历史相似年补充\n",
    "        else:\n",
    "            # for number循环\n",
    "            for number in range(0,numbers):\n",
    "                if start_point < harvest_point: # 同年生长\n",
    "                    WeekList_len = len(list(range(1,harvest_point-start_point+1)))# 设定的hisWeekList好像不包括了start_point周\n",
    "                    forecast_point = start_point+WeekList_len-int(S2S_leadweek[9:])+1\n",
    "                    end_point = forecast_point+6  # 不包括最后一周\n",
    "                    weeklist_keep =  list(range(start_point,end_point))\n",
    "                    weeklist_hiscom =  list(range(end_point,harvest_point+1))\n",
    "                else:\n",
    "                    WeekList_len =len(range(1,harvest_point-start_point+1+46))+len(range(1,harvest_point-start_point+1))\n",
    "                    forecast_point = start_point+WeekList_len-int(S2S_leadweek[9:])+1\n",
    "                    end_point = forecast_point + 6 - 46 if forecast_point + 6 > 46 else forecast_point + 6\n",
    "                    weeklist_keep =  list(range(start_point,47))+list(range(1,end_point))  if start_point > end_point else list(range(start_point,end_point))\n",
    "                    weeklist_hiscom = list(range(end_point,47))+list(range(1,harvest_point+1))  if end_point > harvest_point else list(range(end_point,harvest_point+1))\n",
    "                    \n",
    "    \n",
    "                S2S_outputpath = os.path.join(inputpath_base,'02_S2S','05_WeekData','01_S2S','VI_Like',region,leadweek)\n",
    "                data_S2S_new_update= pd.read_csv(os.path.join(S2S_outputpath,'number'+ str(number) + '.csv'))\n",
    "                for climate1 in TimeFeatures_sel:\n",
    "                    weeklist_keep_feature =[f'Week{week}_{climate1}' for week in weeklist_keep]\n",
    "                    weeklist_hiscom_feature  =[f'Week{week}_{climate1}' for week in weeklist_hiscom]\n",
    "                    weeklist_keep_feature_mean_hist = data_his_new_update[weeklist_keep_feature].mean()\n",
    "                    weeklist_keep_feature_mean_S2S = data_S2S_new_update[weeklist_keep_feature].mean()\n",
    "                    distance, path = fastdtw(weeklist_keep_feature_mean_S2S, weeklist_keep_feature_mean_hist)# 预报当前周到收获的日子\n",
    "                    data.append([number,S2S_leadweek,year_hist,climate1,distance]) \n",
    "                    \n",
    "dtw_distances = pd.DataFrame(data, columns=['number','Leadweek','hist_year','climate','distance'])            \n",
    "dtw_distances.to_csv(os.path.join(inputpath_base,'02_S2S','similaryears_finds.csv'),index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68c0e9-6efd-4d74-830b-953dfe55ffe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878618b3-642c-494e-92aa-477bd92190b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 按照所以选择的指标计算一个最相似的年份，补充预报后面的数据#############################\n",
    "hist_start_year = Forecastyear-30;hist_end_year = Forecastyear-1;\n",
    "min_distance_idx = dtw_distances.groupby(['number', 'Leadweek'])['distance'].idxmin()\n",
    "# 通过索引获取对应的 hist_year 和其他列（如果需要的话）\n",
    "min_distance_years = dtw_distances.loc[min_distance_idx, ['number', 'Leadweek', 'hist_year', 'distance']]\n",
    "\n",
    "\n",
    "dtw_distances = pd.read_csv(os.path.join(inputpath_base,'02_S2S','similaryears_finds.csv'))\n",
    "dataweeks = find_weeks(inputpath_base,forecastDataList)\n",
    "\n",
    "unique_values = {}\n",
    "for key, value in dataweeks.items():\n",
    "    if value not in unique_values.values():\n",
    "        unique_values[key] = value\n",
    "\n",
    "simple_week = {key: f\"leadweek_{len(dataweeks) - idx}\" for idx, key in enumerate(unique_values.keys())}   \n",
    "for _, S2S_leadweek in simple_week.items():# 注意修改这里改成批量算法 #[0:1]\n",
    "    S2S_outputpath1 = os.path.join(inputpath_base,'02_S2S','06_buildmodel','01_S2S','VI_Like',region,S2S_leadweek)\n",
    "    os.makedirs(S2S_outputpath1,exist_ok=True)\n",
    "    if int(S2S_leadweek[9:])-6<=0:\n",
    "        for number in range(0,numbers):\n",
    "            S2S_outputpath = os.path.join(inputpath_base,'02_S2S','05_WeekData','01_S2S','VI_Like',region,S2S_leadweek)\n",
    "            data_S2S_new_update= pd.read_csv(os.path.join(S2S_outputpath,'number'+ str(number) + '.csv'))\n",
    "            S2S_outputpath1 = os.path.join(inputpath_base,'02_S2S','06_buildmodel','01_S2S','VI_Like',region,S2S_leadweek)\n",
    "            data_S2S_new_update.to_csv(os.path.join(S2S_outputpath1,'number'+ str(number) + '.csv'))  \n",
    "    else:\n",
    "        # for number循环\n",
    "        for number in range(0,numbers):\n",
    "            if start_point < harvest_point: # 同年生长\n",
    "                WeekList_len = len(list(range(1,harvest_point-start_point+1)))# 设定的hisWeekList好像不包括了start_point周\n",
    "                forecast_point = start_point+WeekList_len-int(S2S_leadweek[9:])+1\n",
    "                end_point = forecast_point+6  # 不包括最后一周\n",
    "                weeklist_keep =  list(range(start_point,end_point))\n",
    "                weeklist_hiscom =  list(range(end_point,harvest_point+1))\n",
    "            else:\n",
    "                WeekList_len =len(range(1,harvest_point-start_point+1+46))+len(range(1,harvest_point-start_point+1))\n",
    "                forecast_point = start_point+WeekList_len-int(S2S_leadweek[9:])+1\n",
    "                end_point = forecast_point + 6 - 46 if forecast_point + 6 > 46 else forecast_point + 6\n",
    "                weeklist_keep =  list(range(start_point,47))+list(range(1,end_point))  if start_point > end_point else list(range(start_point,end_point))\n",
    "                weeklist_hiscom = list(range(end_point,47))+list(range(1,harvest_point+1))  if end_point > harvest_point else list(range(end_point,harvest_point+1))\n",
    "                \n",
    "    \n",
    "            S2S_outputpath = os.path.join(inputpath_base,'02_S2S','05_WeekData','01_S2S','VI_Like',region,S2S_leadweek)\n",
    "            data_S2S_new_update= pd.read_csv(os.path.join(S2S_outputpath,'number'+ str(number) + '.csv'))\n",
    "            similar_years = int(min_distance_years[(min_distance_years['number']==number)&(min_distance_years['Leadweek']==S2S_leadweek)]['hist_year'].values)\n",
    "            hist_outputpath1 = os.path.join(inputpath_base,'02_S2S','05_WeekData','02_hist',region)\n",
    "            data_his_new_update = pd.read_csv(os.path.join(hist_outputpath1,'hist_'+str(similar_years)+'.csv'))\n",
    "            data_S2S_new_update_copy = data_S2S_new_update.copy()\n",
    "            data_S2S_new_update_copy = data_S2S_new_update.set_index(['idJoin']);\n",
    "            data_his_new_update = data_his_new_update.set_index(['idJoin']);\n",
    "            weeklist_hiscom = ['Week'+str(week)+'_' for week in weeklist_hiscom]\n",
    "            weeklist_hiscom_all= [col for col in data_S2S_new_update.columns if any(feature in col for feature in weeklist_hiscom)]\n",
    "            weeklist_hiscom_all = [item for item in weeklist_hiscom_all if VI_select2 not in item]\n",
    "            \n",
    "            data_S2S_new_update_copy[weeklist_hiscom_all] = data_his_new_update[weeklist_hiscom_all];\n",
    "           # S2S_outputpath = os.path.join(inputpath_base,'02_S2S','06_buildmodel','01_S2S','VI_Like',region,leadweek)\n",
    "           # os.makedirs(S2S_outputpath,exist_ok=True)\n",
    "\n",
    "            data_S2S_new_update_copy.to_csv(os.path.join(S2S_outputpath1,'number'+ str(number) + '.csv'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b69e5f-efff-4638-9635-119d59499542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93b28a-8856-46ed-bb65-f2b42dc14a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869286-1470-4756-a20a-f456e6fc3522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc081f2-a54b-4fa7-a569-8547936db8ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################寻找最相似的前五年的#############################\n",
    "min_distance_years_top_5 = dtw_distances[['number','Leadweek','hist_year','distance']].groupby(['number', 'Leadweek']).apply(\n",
    "    lambda group: group.nsmallest(5, 'distance')\n",
    ").reset_index(drop=True)\n",
    "min_distance_years_top_5[(min_distance_years_top_5['number']==0)&(min_distance_years_top_5['Leadweek']=='leadweek_10')]\n",
    "\n",
    "dtw_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e707c673-34da-411a-b6a1-057f67abb05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\\\\\SCI\\\\SCI9_1\\\\02_data\\\\02_Wheat\\\\09_European\\\\02_S2S\\\\05_WeekData\\\\02_hist\\\\I\\\\hist_1992.csv'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(hist_outputpath1,'hist_'+str(similar_years)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "342bc131-209d-4351-9c27-fb23c1ad9fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dc43171f-fee0-494d-a5f6-8b32300a71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead_8  45, 46, 1, 2, 3, 4\n",
    "# lead_9  44, 45, 46, 1, 2, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003465aa-126b-4252-b6fe-13b001bdafee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec523220-b0c2-41aa-b301-6881299824dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week19_SPEI</th>\n",
       "      <th>Week20_SPEI</th>\n",
       "      <th>Week21_SPEI</th>\n",
       "      <th>Week22_SPEI</th>\n",
       "      <th>Week23_SPEI</th>\n",
       "      <th>Week24_SPEI</th>\n",
       "      <th>Week25_SPEI</th>\n",
       "      <th>Week26_SPEI</th>\n",
       "      <th>Week27_SPEI</th>\n",
       "      <th>Week28_SPEI</th>\n",
       "      <th>...</th>\n",
       "      <th>Week19_Pre</th>\n",
       "      <th>Week20_Pre</th>\n",
       "      <th>Week21_Pre</th>\n",
       "      <th>Week22_Pre</th>\n",
       "      <th>Week23_Pre</th>\n",
       "      <th>Week24_Pre</th>\n",
       "      <th>Week25_Pre</th>\n",
       "      <th>Week26_Pre</th>\n",
       "      <th>Week27_Pre</th>\n",
       "      <th>Week28_Pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idJoin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT32</th>\n",
       "      <td>0.408049</td>\n",
       "      <td>0.317654</td>\n",
       "      <td>0.230743</td>\n",
       "      <td>0.134998</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>-0.046029</td>\n",
       "      <td>-0.137463</td>\n",
       "      <td>-0.226015</td>\n",
       "      <td>-0.316863</td>\n",
       "      <td>-0.404500</td>\n",
       "      <td>...</td>\n",
       "      <td>25.071520</td>\n",
       "      <td>41.087120</td>\n",
       "      <td>71.494306</td>\n",
       "      <td>50.573064</td>\n",
       "      <td>35.502615</td>\n",
       "      <td>49.802822</td>\n",
       "      <td>28.829998</td>\n",
       "      <td>64.776065</td>\n",
       "      <td>31.749152</td>\n",
       "      <td>69.990794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT11</th>\n",
       "      <td>0.351903</td>\n",
       "      <td>0.272603</td>\n",
       "      <td>0.197916</td>\n",
       "      <td>0.125513</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>-0.030291</td>\n",
       "      <td>-0.111182</td>\n",
       "      <td>-0.189610</td>\n",
       "      <td>-0.270201</td>\n",
       "      <td>-0.353404</td>\n",
       "      <td>...</td>\n",
       "      <td>4.850283</td>\n",
       "      <td>17.734279</td>\n",
       "      <td>45.574093</td>\n",
       "      <td>46.512334</td>\n",
       "      <td>6.481053</td>\n",
       "      <td>107.623962</td>\n",
       "      <td>10.463139</td>\n",
       "      <td>36.278669</td>\n",
       "      <td>2.860229</td>\n",
       "      <td>13.403733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT33</th>\n",
       "      <td>0.466780</td>\n",
       "      <td>0.374567</td>\n",
       "      <td>0.284014</td>\n",
       "      <td>0.178718</td>\n",
       "      <td>0.086796</td>\n",
       "      <td>-0.004516</td>\n",
       "      <td>-0.096610</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>-0.280840</td>\n",
       "      <td>-0.369457</td>\n",
       "      <td>...</td>\n",
       "      <td>23.096828</td>\n",
       "      <td>60.722902</td>\n",
       "      <td>71.302267</td>\n",
       "      <td>48.175932</td>\n",
       "      <td>41.957419</td>\n",
       "      <td>57.514868</td>\n",
       "      <td>38.200027</td>\n",
       "      <td>51.286408</td>\n",
       "      <td>37.840401</td>\n",
       "      <td>73.517192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT34</th>\n",
       "      <td>0.429006</td>\n",
       "      <td>0.339865</td>\n",
       "      <td>0.252458</td>\n",
       "      <td>0.153270</td>\n",
       "      <td>0.063298</td>\n",
       "      <td>-0.025785</td>\n",
       "      <td>-0.116760</td>\n",
       "      <td>-0.207941</td>\n",
       "      <td>-0.298268</td>\n",
       "      <td>-0.385554</td>\n",
       "      <td>...</td>\n",
       "      <td>28.317897</td>\n",
       "      <td>75.382253</td>\n",
       "      <td>80.504027</td>\n",
       "      <td>55.899956</td>\n",
       "      <td>41.167696</td>\n",
       "      <td>56.112149</td>\n",
       "      <td>30.839067</td>\n",
       "      <td>42.011143</td>\n",
       "      <td>34.130929</td>\n",
       "      <td>70.382639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT22</th>\n",
       "      <td>0.362058</td>\n",
       "      <td>0.279639</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>0.124048</td>\n",
       "      <td>0.039905</td>\n",
       "      <td>-0.038841</td>\n",
       "      <td>-0.122426</td>\n",
       "      <td>-0.201726</td>\n",
       "      <td>-0.284262</td>\n",
       "      <td>-0.368056</td>\n",
       "      <td>...</td>\n",
       "      <td>17.432355</td>\n",
       "      <td>21.846918</td>\n",
       "      <td>52.653036</td>\n",
       "      <td>45.285905</td>\n",
       "      <td>13.799507</td>\n",
       "      <td>83.794351</td>\n",
       "      <td>17.805066</td>\n",
       "      <td>59.125597</td>\n",
       "      <td>20.082834</td>\n",
       "      <td>34.459557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE12</th>\n",
       "      <td>0.369023</td>\n",
       "      <td>0.293792</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.139246</td>\n",
       "      <td>0.061359</td>\n",
       "      <td>-0.020481</td>\n",
       "      <td>-0.102164</td>\n",
       "      <td>-0.181437</td>\n",
       "      <td>-0.267401</td>\n",
       "      <td>-0.345071</td>\n",
       "      <td>...</td>\n",
       "      <td>6.343060</td>\n",
       "      <td>32.012591</td>\n",
       "      <td>27.270656</td>\n",
       "      <td>14.774992</td>\n",
       "      <td>21.969098</td>\n",
       "      <td>8.994144</td>\n",
       "      <td>18.501852</td>\n",
       "      <td>15.697783</td>\n",
       "      <td>0.800087</td>\n",
       "      <td>22.877628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE31</th>\n",
       "      <td>0.393021</td>\n",
       "      <td>0.316925</td>\n",
       "      <td>0.237848</td>\n",
       "      <td>0.158581</td>\n",
       "      <td>0.081863</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>-0.083704</td>\n",
       "      <td>-0.163548</td>\n",
       "      <td>-0.250621</td>\n",
       "      <td>-0.329829</td>\n",
       "      <td>...</td>\n",
       "      <td>8.032646</td>\n",
       "      <td>43.882330</td>\n",
       "      <td>26.354470</td>\n",
       "      <td>16.036839</td>\n",
       "      <td>53.360216</td>\n",
       "      <td>14.380335</td>\n",
       "      <td>25.319454</td>\n",
       "      <td>27.117401</td>\n",
       "      <td>0.571944</td>\n",
       "      <td>27.397082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE23</th>\n",
       "      <td>0.341699</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.193989</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>-0.032701</td>\n",
       "      <td>-0.111864</td>\n",
       "      <td>-0.188642</td>\n",
       "      <td>-0.271562</td>\n",
       "      <td>-0.347819</td>\n",
       "      <td>...</td>\n",
       "      <td>10.691078</td>\n",
       "      <td>37.226896</td>\n",
       "      <td>21.998423</td>\n",
       "      <td>28.406346</td>\n",
       "      <td>43.895362</td>\n",
       "      <td>19.456904</td>\n",
       "      <td>19.244330</td>\n",
       "      <td>21.156696</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>33.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE22</th>\n",
       "      <td>0.340994</td>\n",
       "      <td>0.268944</td>\n",
       "      <td>0.194038</td>\n",
       "      <td>0.119387</td>\n",
       "      <td>0.045147</td>\n",
       "      <td>-0.033739</td>\n",
       "      <td>-0.111206</td>\n",
       "      <td>-0.188355</td>\n",
       "      <td>-0.269447</td>\n",
       "      <td>-0.346764</td>\n",
       "      <td>...</td>\n",
       "      <td>12.873478</td>\n",
       "      <td>35.929575</td>\n",
       "      <td>11.714310</td>\n",
       "      <td>12.151026</td>\n",
       "      <td>38.225015</td>\n",
       "      <td>3.871426</td>\n",
       "      <td>25.695477</td>\n",
       "      <td>17.154188</td>\n",
       "      <td>0.256013</td>\n",
       "      <td>33.830015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TR2</th>\n",
       "      <td>0.381070</td>\n",
       "      <td>0.305105</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>0.147862</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>-0.096520</td>\n",
       "      <td>-0.181826</td>\n",
       "      <td>-0.260832</td>\n",
       "      <td>-0.347499</td>\n",
       "      <td>...</td>\n",
       "      <td>7.815443</td>\n",
       "      <td>11.918062</td>\n",
       "      <td>9.546724</td>\n",
       "      <td>21.636890</td>\n",
       "      <td>21.098765</td>\n",
       "      <td>4.625079</td>\n",
       "      <td>5.295597</td>\n",
       "      <td>1.173964</td>\n",
       "      <td>28.684066</td>\n",
       "      <td>1.519959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Week19_SPEI  Week20_SPEI  Week21_SPEI  Week22_SPEI  Week23_SPEI  \\\n",
       "idJoin                                                                    \n",
       "AT32       0.408049     0.317654     0.230743     0.134998     0.044302   \n",
       "AT11       0.351903     0.272603     0.197916     0.125513     0.044137   \n",
       "AT33       0.466780     0.374567     0.284014     0.178718     0.086796   \n",
       "AT34       0.429006     0.339865     0.252458     0.153270     0.063298   \n",
       "AT22       0.362058     0.279639     0.201353     0.124048     0.039905   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "SE12       0.369023     0.293792     0.216666     0.139246     0.061359   \n",
       "SE31       0.393021     0.316925     0.237848     0.158581     0.081863   \n",
       "SE23       0.341699     0.268817     0.193989     0.119873     0.045907   \n",
       "SE22       0.340994     0.268944     0.194038     0.119387     0.045147   \n",
       "TR2        0.381070     0.305105     0.224779     0.147862     0.068841   \n",
       "\n",
       "        Week24_SPEI  Week25_SPEI  Week26_SPEI  Week27_SPEI  Week28_SPEI  ...  \\\n",
       "idJoin                                                                   ...   \n",
       "AT32      -0.046029    -0.137463    -0.226015    -0.316863    -0.404500  ...   \n",
       "AT11      -0.030291    -0.111182    -0.189610    -0.270201    -0.353404  ...   \n",
       "AT33      -0.004516    -0.096610    -0.189015    -0.280840    -0.369457  ...   \n",
       "AT34      -0.025785    -0.116760    -0.207941    -0.298268    -0.385554  ...   \n",
       "AT22      -0.038841    -0.122426    -0.201726    -0.284262    -0.368056  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "SE12      -0.020481    -0.102164    -0.181437    -0.267401    -0.345071  ...   \n",
       "SE31      -0.000945    -0.083704    -0.163548    -0.250621    -0.329829  ...   \n",
       "SE23      -0.032701    -0.111864    -0.188642    -0.271562    -0.347819  ...   \n",
       "SE22      -0.033739    -0.111206    -0.188355    -0.269447    -0.346764  ...   \n",
       "TR2       -0.015275    -0.096520    -0.181826    -0.260832    -0.347499  ...   \n",
       "\n",
       "        Week19_Pre  Week20_Pre  Week21_Pre  Week22_Pre  Week23_Pre  \\\n",
       "idJoin                                                               \n",
       "AT32     25.071520   41.087120   71.494306   50.573064   35.502615   \n",
       "AT11      4.850283   17.734279   45.574093   46.512334    6.481053   \n",
       "AT33     23.096828   60.722902   71.302267   48.175932   41.957419   \n",
       "AT34     28.317897   75.382253   80.504027   55.899956   41.167696   \n",
       "AT22     17.432355   21.846918   52.653036   45.285905   13.799507   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "SE12      6.343060   32.012591   27.270656   14.774992   21.969098   \n",
       "SE31      8.032646   43.882330   26.354470   16.036839   53.360216   \n",
       "SE23     10.691078   37.226896   21.998423   28.406346   43.895362   \n",
       "SE22     12.873478   35.929575   11.714310   12.151026   38.225015   \n",
       "TR2       7.815443   11.918062    9.546724   21.636890   21.098765   \n",
       "\n",
       "        Week24_Pre  Week25_Pre  Week26_Pre  Week27_Pre  Week28_Pre  \n",
       "idJoin                                                              \n",
       "AT32     49.802822   28.829998   64.776065   31.749152   69.990794  \n",
       "AT11    107.623962   10.463139   36.278669    2.860229   13.403733  \n",
       "AT33     57.514868   38.200027   51.286408   37.840401   73.517192  \n",
       "AT34     56.112149   30.839067   42.011143   34.130929   70.382639  \n",
       "AT22     83.794351   17.805066   59.125597   20.082834   34.459557  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "SE12      8.994144   18.501852   15.697783    0.800087   22.877628  \n",
       "SE31     14.380335   25.319454   27.117401    0.571944   27.397082  \n",
       "SE23     19.456904   19.244330   21.156696    0.719964   33.797604  \n",
       "SE22      3.871426   25.695477   17.154188    0.256013   33.830015  \n",
       "TR2       4.625079    5.295597    1.173964   28.684066    1.519959  \n",
       "\n",
       "[208 rows x 70 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_his_new_update[weeklist_hiscom_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "12966a90-4b69-40b8-b82f-13e68ee9cf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week19_SPEI</th>\n",
       "      <th>Week20_SPEI</th>\n",
       "      <th>Week21_SPEI</th>\n",
       "      <th>Week22_SPEI</th>\n",
       "      <th>Week23_SPEI</th>\n",
       "      <th>Week24_SPEI</th>\n",
       "      <th>Week25_SPEI</th>\n",
       "      <th>Week26_SPEI</th>\n",
       "      <th>Week27_SPEI</th>\n",
       "      <th>Week28_SPEI</th>\n",
       "      <th>...</th>\n",
       "      <th>Week19_Pre</th>\n",
       "      <th>Week20_Pre</th>\n",
       "      <th>Week21_Pre</th>\n",
       "      <th>Week22_Pre</th>\n",
       "      <th>Week23_Pre</th>\n",
       "      <th>Week24_Pre</th>\n",
       "      <th>Week25_Pre</th>\n",
       "      <th>Week26_Pre</th>\n",
       "      <th>Week27_Pre</th>\n",
       "      <th>Week28_Pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idJoin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT11</th>\n",
       "      <td>0.378546</td>\n",
       "      <td>0.299539</td>\n",
       "      <td>0.214343</td>\n",
       "      <td>0.136893</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>-0.028318</td>\n",
       "      <td>-0.104630</td>\n",
       "      <td>-0.189960</td>\n",
       "      <td>-0.268945</td>\n",
       "      <td>-0.339080</td>\n",
       "      <td>...</td>\n",
       "      <td>43.052968</td>\n",
       "      <td>5.913522</td>\n",
       "      <td>4.578223</td>\n",
       "      <td>56.943066</td>\n",
       "      <td>6.227609</td>\n",
       "      <td>5.700843</td>\n",
       "      <td>25.590212</td>\n",
       "      <td>20.853666</td>\n",
       "      <td>32.635587</td>\n",
       "      <td>36.962891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT12</th>\n",
       "      <td>0.372131</td>\n",
       "      <td>0.293921</td>\n",
       "      <td>0.210468</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>-0.031043</td>\n",
       "      <td>-0.106907</td>\n",
       "      <td>-0.191283</td>\n",
       "      <td>-0.269091</td>\n",
       "      <td>-0.351541</td>\n",
       "      <td>...</td>\n",
       "      <td>30.556206</td>\n",
       "      <td>13.305013</td>\n",
       "      <td>12.525048</td>\n",
       "      <td>46.673459</td>\n",
       "      <td>5.005720</td>\n",
       "      <td>4.043101</td>\n",
       "      <td>24.757369</td>\n",
       "      <td>21.770578</td>\n",
       "      <td>36.404958</td>\n",
       "      <td>8.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT13</th>\n",
       "      <td>0.377216</td>\n",
       "      <td>0.299195</td>\n",
       "      <td>0.214661</td>\n",
       "      <td>0.137157</td>\n",
       "      <td>0.052376</td>\n",
       "      <td>-0.027251</td>\n",
       "      <td>-0.102619</td>\n",
       "      <td>-0.187918</td>\n",
       "      <td>-0.266642</td>\n",
       "      <td>-0.368250</td>\n",
       "      <td>...</td>\n",
       "      <td>27.988845</td>\n",
       "      <td>13.013152</td>\n",
       "      <td>10.023957</td>\n",
       "      <td>53.101030</td>\n",
       "      <td>6.708251</td>\n",
       "      <td>2.404604</td>\n",
       "      <td>31.635641</td>\n",
       "      <td>17.140076</td>\n",
       "      <td>30.350946</td>\n",
       "      <td>39.494141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT21</th>\n",
       "      <td>0.344479</td>\n",
       "      <td>0.265866</td>\n",
       "      <td>0.187785</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>-0.049602</td>\n",
       "      <td>-0.126448</td>\n",
       "      <td>-0.208941</td>\n",
       "      <td>-0.283995</td>\n",
       "      <td>-0.353736</td>\n",
       "      <td>...</td>\n",
       "      <td>55.339939</td>\n",
       "      <td>7.312349</td>\n",
       "      <td>34.588423</td>\n",
       "      <td>47.550913</td>\n",
       "      <td>24.407311</td>\n",
       "      <td>26.520981</td>\n",
       "      <td>27.039461</td>\n",
       "      <td>23.984824</td>\n",
       "      <td>62.519919</td>\n",
       "      <td>42.664063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT22</th>\n",
       "      <td>0.359433</td>\n",
       "      <td>0.280675</td>\n",
       "      <td>0.198703</td>\n",
       "      <td>0.121564</td>\n",
       "      <td>0.038662</td>\n",
       "      <td>-0.038861</td>\n",
       "      <td>-0.114958</td>\n",
       "      <td>-0.199031</td>\n",
       "      <td>-0.274762</td>\n",
       "      <td>-0.355612</td>\n",
       "      <td>...</td>\n",
       "      <td>62.430359</td>\n",
       "      <td>9.096199</td>\n",
       "      <td>11.554838</td>\n",
       "      <td>43.601207</td>\n",
       "      <td>19.967512</td>\n",
       "      <td>21.879918</td>\n",
       "      <td>27.018040</td>\n",
       "      <td>17.007322</td>\n",
       "      <td>53.959546</td>\n",
       "      <td>17.478515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE31</th>\n",
       "      <td>0.348896</td>\n",
       "      <td>0.272956</td>\n",
       "      <td>0.197666</td>\n",
       "      <td>0.120931</td>\n",
       "      <td>0.043587</td>\n",
       "      <td>-0.031823</td>\n",
       "      <td>-0.108883</td>\n",
       "      <td>-0.191004</td>\n",
       "      <td>-0.270605</td>\n",
       "      <td>-0.333621</td>\n",
       "      <td>...</td>\n",
       "      <td>31.375346</td>\n",
       "      <td>26.210009</td>\n",
       "      <td>24.781536</td>\n",
       "      <td>19.667035</td>\n",
       "      <td>12.529726</td>\n",
       "      <td>19.681955</td>\n",
       "      <td>19.963743</td>\n",
       "      <td>14.792492</td>\n",
       "      <td>14.670331</td>\n",
       "      <td>26.217773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK01</th>\n",
       "      <td>0.385434</td>\n",
       "      <td>0.306823</td>\n",
       "      <td>0.222257</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.098224</td>\n",
       "      <td>-0.182930</td>\n",
       "      <td>-0.263245</td>\n",
       "      <td>-0.342011</td>\n",
       "      <td>...</td>\n",
       "      <td>37.278366</td>\n",
       "      <td>11.012713</td>\n",
       "      <td>10.027587</td>\n",
       "      <td>50.345584</td>\n",
       "      <td>3.058030</td>\n",
       "      <td>2.959487</td>\n",
       "      <td>22.625322</td>\n",
       "      <td>22.536374</td>\n",
       "      <td>22.714922</td>\n",
       "      <td>27.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK02</th>\n",
       "      <td>0.378208</td>\n",
       "      <td>0.300011</td>\n",
       "      <td>0.215970</td>\n",
       "      <td>0.137516</td>\n",
       "      <td>0.052806</td>\n",
       "      <td>-0.027222</td>\n",
       "      <td>-0.103220</td>\n",
       "      <td>-0.185984</td>\n",
       "      <td>-0.265881</td>\n",
       "      <td>-0.344494</td>\n",
       "      <td>...</td>\n",
       "      <td>43.579727</td>\n",
       "      <td>11.488854</td>\n",
       "      <td>12.445776</td>\n",
       "      <td>45.730191</td>\n",
       "      <td>2.859425</td>\n",
       "      <td>1.495537</td>\n",
       "      <td>21.852090</td>\n",
       "      <td>27.156459</td>\n",
       "      <td>26.103275</td>\n",
       "      <td>18.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK03</th>\n",
       "      <td>0.375680</td>\n",
       "      <td>0.296848</td>\n",
       "      <td>0.212021</td>\n",
       "      <td>0.132818</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>-0.030669</td>\n",
       "      <td>-0.106990</td>\n",
       "      <td>-0.187286</td>\n",
       "      <td>-0.265617</td>\n",
       "      <td>-0.348444</td>\n",
       "      <td>...</td>\n",
       "      <td>46.073651</td>\n",
       "      <td>8.267073</td>\n",
       "      <td>10.198250</td>\n",
       "      <td>34.823728</td>\n",
       "      <td>4.258134</td>\n",
       "      <td>4.730501</td>\n",
       "      <td>17.249563</td>\n",
       "      <td>24.844960</td>\n",
       "      <td>38.616156</td>\n",
       "      <td>22.107422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK04</th>\n",
       "      <td>0.371777</td>\n",
       "      <td>0.292809</td>\n",
       "      <td>0.207046</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>-0.034135</td>\n",
       "      <td>-0.111104</td>\n",
       "      <td>-0.189586</td>\n",
       "      <td>-0.268923</td>\n",
       "      <td>-0.339685</td>\n",
       "      <td>...</td>\n",
       "      <td>46.835763</td>\n",
       "      <td>9.916658</td>\n",
       "      <td>9.022992</td>\n",
       "      <td>33.769911</td>\n",
       "      <td>12.159632</td>\n",
       "      <td>16.070231</td>\n",
       "      <td>10.391138</td>\n",
       "      <td>34.285675</td>\n",
       "      <td>31.834879</td>\n",
       "      <td>30.914063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Week19_SPEI  Week20_SPEI  Week21_SPEI  Week22_SPEI  Week23_SPEI  \\\n",
       "idJoin                                                                    \n",
       "AT11       0.378546     0.299539     0.214343     0.136893     0.051822   \n",
       "AT12       0.372131     0.293921     0.210468     0.132705     0.048054   \n",
       "AT13       0.377216     0.299195     0.214661     0.137157     0.052376   \n",
       "AT21       0.344479     0.265866     0.187785     0.111173     0.028251   \n",
       "AT22       0.359433     0.280675     0.198703     0.121564     0.038662   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "SE31       0.348896     0.272956     0.197666     0.120931     0.043587   \n",
       "SK01       0.385434     0.306823     0.222257     0.143939     0.058719   \n",
       "SK02       0.378208     0.300011     0.215970     0.137516     0.052806   \n",
       "SK03       0.375680     0.296848     0.212021     0.132818     0.048599   \n",
       "SK04       0.371777     0.292809     0.207046     0.126882     0.043194   \n",
       "\n",
       "        Week24_SPEI  Week25_SPEI  Week26_SPEI  Week27_SPEI  Week28_SPEI  ...  \\\n",
       "idJoin                                                                   ...   \n",
       "AT11      -0.028318    -0.104630    -0.189960    -0.268945    -0.339080  ...   \n",
       "AT12      -0.031043    -0.106907    -0.191283    -0.269091    -0.351541  ...   \n",
       "AT13      -0.027251    -0.102619    -0.187918    -0.266642    -0.368250  ...   \n",
       "AT21      -0.049602    -0.126448    -0.208941    -0.283995    -0.353736  ...   \n",
       "AT22      -0.038861    -0.114958    -0.199031    -0.274762    -0.355612  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "SE31      -0.031823    -0.108883    -0.191004    -0.270605    -0.333621  ...   \n",
       "SK01      -0.021740    -0.098224    -0.182930    -0.263245    -0.342011  ...   \n",
       "SK02      -0.027222    -0.103220    -0.185984    -0.265881    -0.344494  ...   \n",
       "SK03      -0.030669    -0.106990    -0.187286    -0.265617    -0.348444  ...   \n",
       "SK04      -0.034135    -0.111104    -0.189586    -0.268923    -0.339685  ...   \n",
       "\n",
       "        Week19_Pre  Week20_Pre  Week21_Pre  Week22_Pre  Week23_Pre  \\\n",
       "idJoin                                                               \n",
       "AT11     43.052968    5.913522    4.578223   56.943066    6.227609   \n",
       "AT12     30.556206   13.305013   12.525048   46.673459    5.005720   \n",
       "AT13     27.988845   13.013152   10.023957   53.101030    6.708251   \n",
       "AT21     55.339939    7.312349   34.588423   47.550913   24.407311   \n",
       "AT22     62.430359    9.096199   11.554838   43.601207   19.967512   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "SE31     31.375346   26.210009   24.781536   19.667035   12.529726   \n",
       "SK01     37.278366   11.012713   10.027587   50.345584    3.058030   \n",
       "SK02     43.579727   11.488854   12.445776   45.730191    2.859425   \n",
       "SK03     46.073651    8.267073   10.198250   34.823728    4.258134   \n",
       "SK04     46.835763    9.916658    9.022992   33.769911   12.159632   \n",
       "\n",
       "        Week24_Pre  Week25_Pre  Week26_Pre  Week27_Pre  Week28_Pre  \n",
       "idJoin                                                              \n",
       "AT11      5.700843   25.590212   20.853666   32.635587   36.962891  \n",
       "AT12      4.043101   24.757369   21.770578   36.404958    8.632812  \n",
       "AT13      2.404604   31.635641   17.140076   30.350946   39.494141  \n",
       "AT21     26.520981   27.039461   23.984824   62.519919   42.664063  \n",
       "AT22     21.879918   27.018040   17.007322   53.959546   17.478515  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "SE31     19.681955   19.963743   14.792492   14.670331   26.217773  \n",
       "SK01      2.959487   22.625322   22.536374   22.714922   27.515625  \n",
       "SK02      1.495537   21.852090   27.156459   26.103275   18.910156  \n",
       "SK03      4.730501   17.249563   24.844960   38.616156   22.107422  \n",
       "SK04     16.070231   10.391138   34.285675   31.834879   30.914063  \n",
       "\n",
       "[170 rows x 70 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_S2S_new_update.set_index(['idJoin'])[weeklist_hiscom_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa2ec6-a3b5-4018-ad39-3dae420adb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shap_env)",
   "language": "python",
   "name": "shap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
